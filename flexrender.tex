
% Cal Poly Thesis
% 
% based on UC Thesis format
%
% modified by Mark Barry 2/07.
%




\documentclass[12pt]{ucthesis}

%\newif\ifpdf
%\ifx\pdfoutput\undefined
%    \pdffalse % we are not running PDFLaTeX
%\else
%\pdfoutput=1 % we are running PDFLaTeX
%\pdftrue \fi

\usepackage{textcomp}
\usepackage{url}
\usepackage{listings}
\lstset{
	language=[Visual]C++,
	keywordstyle=\bfseries\ttfamily\color[rgb]{0,0,1},
	identifierstyle=\ttfamily,
	commentstyle=\color[rgb]{0.133,0.545,0.133},
	stringstyle=\ttfamily\color[rgb]{0.627,0.126,0.941},
	showstringspaces=false,
	basicstyle=\small,
	numberstyle=\footnotesize,
	numbers=left,
	stepnumber=1,
	numbersep=10pt,
	tabsize=2,
	breaklines=true,
	prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
	breakatwhitespace=false,
	aboveskip={1.5\baselineskip},
  columns=fixed,
  upquote=true,
  extendedchars=true
% frame=single,
% backgroundcolor=\color{lbcolor},
}
\usepackage{color}
%\ifpdf

    \usepackage[pdftex]{graphicx}
    % Update title and author below...
    \usepackage[pdftex,plainpages=false,breaklinks=true,colorlinks=true,urlcolor=blue,citecolor=blue,%
                                       linkcolor=blue,bookmarks=true,bookmarksopen=true,%
                                       bookmarksopenlevel=3,pdfstartview=FitV,
                                       pdfauthor=Christopher Gibson,
                                       pdftitle=Point-Based Color Bleeding With Volumes,
                                       pdfkeywords={thesis, masters, cal poly, volume rendering, global illumination}
                                       ]{hyperref}
    %Options with pdfstartview are FitV, FitB and FitH
    \pdfcompresslevel=1

%\else
%    \usepackage{graphicx}
%\fi

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[letterpaper]{geometry}
\usepackage[overload]{textcase}



%%%%%\bibliographystyle{abbrv}

\setlength{\parindent}{0.25in} \setlength{\parskip}{6pt}

\geometry{verbose,nohead,tmargin=1.25in,bmargin=1in,lmargin=1.5in,rmargin=1.3in}

\setcounter{tocdepth}{2}


% Different font in captions (single-spaced, bold) ------------
\newcommand{\captionfonts}{\small\bf\ssp}

\makeatletter  % Allow the use of @ in command names
\long\def\@makecaption#1#2{%
  \vskip\abovecaptionskip
  \sbox\@tempboxa{{\captionfonts #1: #2}}%
  \ifdim \wd\@tempboxa >\hsize
    {\captionfonts #1: #2\par}
  \else
    \hbox to\hsize{\hfil\box\@tempboxa\hfil}%
  \fi
  \vskip\belowcaptionskip}
\makeatother   % Cancel the effect of \makeatletter
% ---------------------------------------

\begin{document}

% Declarations for Front Matter

% Update fields below!
\title{FlexRender: A distributed rendering architecture for ray tracing huge
scenes on commodity hardware.}
\author{Robert Edward Somers}
\degreemonth{June} \degreeyear{2012} \degree{Master of Science}
\defensemonth{June} \defenseyear{2012}
\numberofmembers{3} \chair{Zo\"{e} Wood, Ph.D.} \othermemberA{Chris Lupo, Ph.D.} \othermemberB{Phillip Nico, Ph.D.} \field{Computer Science} \campus{San Luis Obispo}
\copyrightyears{seven}



\maketitle

\begin{frontmatter}

% Custom made for Cal Poly (by Mark Barry, modified by Andrew Tsui).
\copyrightpage

% Custom made for Cal Poly (by Andrew Tsui).
\committeemembershippage

\begin{abstract}

As the quest for more realistic computer graphics marches steadily on, the
demand for rich and detailed imagery is greater than ever. Unfortunately, our
appetite for large and complex geometry is quickly outpacing advances in the
hardware used to render it. Scenes with hundreds of millions or even billions
of polygons are not only desired, they are demanded.

Techniques such as normal mapping and level of detail have attempted to address
the problem by reducing the amount of geometry in a scene. This is problematic
for applications that desire or demand access to the scene's full geometric
complexity at render time. More recently, out-of-core techniques have provided
methods for rendering large scenes when the working set is larger than the
available system memory.

We propose a distributed rendering architecture based on message-passing that
is designed to partition scene geometry across a cluster of commodity machines
in a spatially coherent way, allowing the entire scene to remain in-core and
enabling the construction of hierarchical spatial acceleration structures in
parallel. The results of our implementation show over an order of magnitude
speedup in rendering time compared the traditional approach, while keeping
memory overhead for message queuing around 1\%.

\textbf{TODO: Triple check that claim with the Toy Store scene results.}

\end{abstract}

%\begin{acknowledgements}

%   Thank you...

%\end{acknowledgements}


\tableofcontents


\listoftables

\listoffigures

\end{frontmatter}

\pagestyle{plain}




\renewcommand{\baselinestretch}{1.66}


% ------------- Main chapters here --------------------





\chapter{Introduction}
\label{intro}

\emph{Rendering}, the process of taking the description of a scene and turning
it into a visual image, has advanced at an incredible pace in recent
years. Many techniques have been developed to turn these descriptions into
pixels, and countless more have targeted weaknesses or challenges with those
algorithms. As the field continues to evolve and grow, new algorithms will be
born, others will fall out of favor and die, and some will soldier on. Only
one thing remains constant: The desire to bring our computational models ever
closer to mimicking physical reality.

\section{Geometric Complexity}
\label{complexity}

At the heart of mimicking reality is describing the world we wish to show. In
computer graphics, this has traditionally been done by defining surfaces. While
exciting developments in volume rendering techniques happen on regular basis,
it is unlikely we will abandon using surfaces any time soon. Unfortunately for
volumes, they are inherently an $n^3$ problem (where $n$ is the size of the
volume in one dimension) and $n^3$ is not a particularly friendly number in the
field of Computer Science.

For now and the foreseeable future, it seems, surfaces will be our bread and
butter. Many methods have been developed for describing surfaces to computer
programs, such as level sets, implicitly defined surfaces from mathematical
equations, and curvalinear forms such as parametric splines. The undisputed
champion of surface representations, however, has been the polygonal mesh.
Countless man-years of research and development has yielded efficient
techniques for processing meshes of interconnected polygons at blistering
speeds, and many other surface representations are ultimately converted to a
polygonal mesh at some stage of the rendering pipeline.

Meshes are easy for artists to work with because they represent discrete
points in space and the connectivity between those points (rather than abstract
equations). However, their core advantage is also their core drawback. Because
everything is defined explicitly, meshes with fine levels of detail have
significantly higher storage requirements. Thus, as the demand for higher
visual fidelity increases, the natural tendency is to increase geometric
complexity.

\section{Parallel Rendering}
\label{parallel}

Graphics has long been said to be a problem that is \emph{embarrasingly parallel},
given that many graphics algorithms operate on pixels independently. Graphics
processing units (GPUs) have exploited this fact for many years to achieve
amazing throughput of graphics primitives in real-time. Ray tracing in
particular (discussed more thoroughly in Section \ref{raytracing}) is commonly
paraded as the poster child for parallel processing.

Unfortunately the story is not all unicorns and rainbows. While processor
architectures have become exceedingly parallel and posted impressive
speedups, the memory hierarchy has not had time to catch up. For a processor
to perform well, the CPI, \emph{cycles per instruction}, must remain low to
ensure time is spent doing useful work and not waiting on data.

In current memory hierarchies, data access time can take anywhere from around
12 cycles (4 nanoseconds for an L1 cache hit) to over 300 cycles (100
nanoseconds for main memory). Techniques such as out-of-order execution are
helpful in filling this wasted time, but for memory intensive applications it
can be difficult to fill all the gaps with useful work. Thus, keeping the chips
"hot" by reducing time spent waiting on data is critical to achieve maximum
performance, and is an extremely challenging problem.

\textbf{TODO: graph of latencies in the memory hierarchy}

Because of this fact, there is a lot more to parallel rendering than initially
meets the eye. Graphics may indeed by highly parallel, but its voracious appetite
for memory access is actively working \emph{against} its parallel efficiency on
current architectures.

\section{Our Contribution}
\label{contribution}

This paper presents the architecture of FlexRender, a ray tracer designed for
rendering huge scenes with high geometric complexity on commodity hardware. We
specifically target commodity hardware because it currently has an excellent
cost to performance ratio, but still typically lacks enough memory to fit large
scenes entirely in RAM.

Current strategies for parallelizing a renderer across a cluster of commodity
machines are limited to having each worker compute a separate ``slice" of the
image, but do nothing to manage the high cost associated with large scene
assets.

Thus, our work describes the following core contributions:

\begin{enumerate}
    \item A system for ray tracing which uses the pooled memory of a cluster of
        commodity machines to keep the entire scene in-core.
    \item A method for passing ray messages between workers in the cluster with
        enough state to never require a reply message.
    \item An extension to the stackless BVH traversal algorithm presented by
        Hapala et al. \cite{hapala:2011} that makes it possible to suspend
        traversal at one worker and resume it at another.
    \item A discussion of the concepts involved and an analysis of the resulting
        implementation.
\end{enumerate}

In particular, we show that FlexRender can achieve speedups that exceed an
order of magnitude over the traditional parallelization approach, and can
naturally self-regulate the cluster of workers to keep the memory overhead due
to message queueing around 1\% of each worker's system memory.

\textbf{TODO: Triple check that claim with Toy Store results.}

\chapter{Background}
\label{background}

The FlexRender architecture builds on the four fundamenal building blocks
described here. First, we discuss the linearity of light (Section \ref{radiometry}),
which is critical to understanding why FlexRender produces a correct composite
image from pieces rendered by different workers. Next, we give a general
overview of ray tracing (Section \ref{raytracing}) and bounding volume hierarchies
(Section \ref{bvhs}). Finally, we discuss Morton coding and the Z-order curve
(Section \ref{morton}) which FlexRender uses to distribute scene data amongst the
workers.

\section{Light and Radiometry}
\label{radiometry}

\emph{Radiometry}, the study of propagation of electromagnetic radiation, forms
the basis for many rendering algorithms. Our coverage will be brief, but we will
examine some critical theory that enables the design of FlexRender. For a more
complete treatment of the topic in the context of rendering algorithms, we refer
the reader to \emph{Physically Based Rendering} \cite{pbrt}.

At its core, radiometry is based on modeling light as radiant energy and
operates at the level of geometric optics. In other words, we acknowledge that
light has wave-like properties and visible light occurs within a spectrum of
wavelengths (roughly 400 to 750 nm), but we do not mathematically model it as
a wave. Rather, we model it as a particle of radiant energy. In ray tracers
(discussed in depth in Section \ref{raytracing}) we model the path traveled by a single
particle of light with a ray.

The interesting parts of the radiometry model with respect to FlexRender are the
following observations:

\begin{description}
    \item[Light behaves linearly.] The combined effect of two rays of light
        in a scene is the same as the sum of their independent effects on the
        scene.
    \item[Energy is conserved.] When a ray reflects off of a surface, it can
        never do so with more energy than it started with.
\end{description}

In particular, these assumptions allow us to make the following key
observations, which FlexRender explicitly exploits:

\begin{description}
    \item[The location of computation does not matter.] If the scene is
        distributed across many workers, it makes no difference which worker
        computes the effect of a ray. The sum of all the workers' computations
        will be the same as if all the work was performed on a single worker.
    \item[Transmittance models energy conservation.] If we store the amount of
        energy traveling along a ray (the \emph{transmittance}) with the ray
        itself, we need not know anything about the preceeding rays or state
        that brought this ray into existence. We can compute its contribution
        to the scene independently and ensure that linearity and energy
        conservation are both respected.
\end{description}

\section{Ray Tracing}
\label{raytracing}

\textbf{TODO: general overview}

\section{Bounding Volume Hierarchies}
\label{bvhs}

Bounding volume hierarchies, or BVHs, are essentially an application of binary
search to 3D space. In ray tracing, the vast majority of time is spent
computing intersection tests to determine whether a ray intersects a given
primitive. BVHs allow us to search 3D space for a potential intersection in a
binary tree fashion, pruning off large numbers of primitives with a single
test. Since it is effectively binary search, it is unsurprising that it reduces
intersection searching from linear time $O(n)$ to logarithmic time $O(log\;n)$
(assuming the BVH is well formed).

\textbf{TODO: picture of bvh}

BVHs are trees where each node is defined by a bounding volume, such as a box
or a sphere, that describes the extents of a region of 3D space. All of the
primitives in the scene that are within that region of space are child nodes
in the tree. Each node has two direct children, which also define bounding
volumes within that subregion of space. Nodes which have other bounding volume
nodes as their children are \emph{interior} nodes. \emph{Leaf} nodes in the tree
define a bounding volume around a single primitive.

After the tree structure is built using a typical linked-memory data structure,
it is flattened into a linear array of nodes for storage efficiency and better
cache performance. Flattening is done by walking the tree in a depth-first
traversal. This means that the left-hand child of the node at index $n$ is
located at index $n + 1$ in the array of nodes. Each node stores an offset
index to its right-hand child. Because the indices are relative to the array
and not the array's location in memory, they are safe to pass back and forth
between workers and require no address translation.

To traverse the tree looking for intersections, we begin by testing the root
node's bounding volume for an intersection. If the ray intersects the volume,
we recursively test each of the node's children. Once we hit a leaf node,
we perform an actual ray-primitive intersection test to determine if the ray
hits the primitive.

The traversal algorithm is naturally recursive, but recursive implementations
keep their state on the call stack. In FlexRender, we may need to suspend the
traversal on one worker and resume it on another, so we need all of the
traversal state explicitly exposed. Refactoring it as an iterative traversal
explicitly exposes the state for capturing.

The iterative algorithm still requires a traversal stack of child nodes that
need to be visited on the way back up the tree. Since this stack is unique for
each ray, the entire stack would need to be carried along with each ray. In
addition, the stack could potentially be large if the scene is huge (and thus,
the tree is deep), so it would be ideal if we had a method for traversing the
tree iteratively without the need to maintain a traversal stack.

A method for doing so is described by Hapala et al. in
\emph{Efficient Stack-less BVH Traversal for Ray Tracing} \cite{hapala:2011}.
Their key insight is that if parent links are stored in the tree, the same
traversal can be achieved using a three-state automaton describing the direction
you came from when you reached the current node (i.e. from the \emph{parent},
from the \emph{sibling}, or from the \emph{child}). They show that their
traversal algorithm produces identical tree walks and never retests nodes that
have already been tested.

FlexRender leverages this traversal algorithm due it its low state storage
requirements. Each ray only needs to know the index of the current node it is
traversing (in the array of flattened nodes) and the state of the traversal
automaton. The extensions made to the algorithm to support suspending traversal
and resuming it on another worker are described in Section \ref{traversal}.

\section{Morton Coding and the Z-Order Curve}
\label{morton}

Morton coding is a method for mapping coordinates in multidimensional space to
a single dimension. In particular, walking the multidimensional space with a
Morton coding produces a space-filling Z-order curve.

\textbf{TODO: pictures of Z-order curves}

More concretely, FlexRender needs a way to distribute a large scene to many
workers in a spatially coherent way. If the geometry on each worker consists
of a localized patch of the overall geometry, it allows us minimize communication
between the workers, and thus, only pay the network cost when we absolutely need
to (described in depth in Section \ref{traversal}).

Because the Morton coding produces a spatially coherent traversal of 3D space,
dividing up the 1D Morton code address space among all the workers participating
in the render gives a reasonable assurance of spatial locality for the geometry
sent to each worker.

The Morton coding is relatively simple to implement. For example, say that
we wish to map a point $P$ in a region of 3D space (defined by its bounding extents
$min$ and $max$) to a Morton coded 64-bit integer. Discretizing each axis evenly
allows for 21 bits per axis, yielding a 63-bit address space (and one unused bit
in the integer).

Computing the Morton code is simply a matter of calculating the 21-bit discretized
component of $P$ along each axis, then shifting the components from each axis
into the 64-bit integer one bit at a time in a round robin fashion, from the
most-significant to least-significant bit.

\textbf{TODO: pseudocode listing of morton code computation}

\chapter{Related Work}
\label{relatedwork}

\textbf{TODO}

\section{Big Geometry Workarounds}
\label{managingcomplexity}

\textbf{TODO}

\subsection{Normal Mapping}
\label{normalmaps}

\textbf{TODO: seminal work}

\subsection{Level of Detail}
\label{levelofdetail}

\textbf{TODO: seminal work}

\subsection{Out-of-Core}
\label{outofcore}

\textbf{TODO: dreamworks PBGI paper, panta ray for directional occlusion}

\section{Parallel Rendering}
\label{parallelbg}

\textbf{TODO}

\subsection{Cooperative Networked Rendering}
\label{networked}

\textbf{TODO: how we differ from kilauea (refer to subsections) \cite{kato:2002}}

\subsection{General Purpose GPU Rendering}
\label{gpgpu}

\textbf{TODO: ray batching, parallel BVH construction, branchy/memory drawbacks (shaders)}

\chapter{FlexRender Architecture}
\label{architecture}

In this chapter, we describe the network architecture and roles of the involved
machines in Section \ref{workers}. We discuss the structure of ray messages
passed between workers in Section \ref{fatrays} and briefly cover the design of
the graphics machinery shared between FlexRender and the baseline implementation
in Section \ref{types}. We detail the process of preparing the cluster for
rendering in Section \ref{sync} and Section \ref{parallelbvh}.

At its core, workers in the cluster are just ray processors. We discuss how they
manage ray messages in Section \ref{queues}, how they generate new work with
stable memory usage in Section \ref{primaryrays}, how we decide when and where
to send rays over the network in Section \ref{traversal}, and how shading is computed
when lights and occluders may exist anywhere in the cluster in Section \ref{shading}.

Finally, we wrap up our discussion with how we monitor the progress of the
render in Section \ref{stats} and how we composite the final image from its
components in Section \ref{synthesis}.

\section{Organization and Design}
\label{organization}

\subsection{Workers and the Renderer}
\label{workers}

There are two potential roles a machine can play during the rendering process.

\begin{description}
    \item[Worker] These machines receive a chunk of the scene and act as ray
        processors to compute intersections and shading values. They produce
        an image that is a component of the final render. There may be an
        arbitrary number of them participating in a render.
    \item[Renderer] This machine reads in the scene data and distributes it to
        the workers. Once rendering begins it monitors the status of the each
        worker and halts any potential runaway situations (see Section \ref{primaryrays}).
        When the renderer decides the process is complete, it requests
        the image components from each worker and merges them into the final
        image. There is only a single renderer in any given cluster and it is
        the machine the user directly interacts with.
\end{description}

From a network perspective, the architecture is simply client/server connected
in a star configuration. Each worker exposes a server which receives and
processes messages, and holds client connections open to every other worker for
passing messages around the cluster. The renderer also holds a client connection
to every worker for sending configuration data, preparing up the cluster for rendering
(described in Section \ref{sync}), and monitoring render progress (described in
Section \ref{stats}).

\textbf{TODO: diagram of network architecture}

\subsection{Fat Rays}
\label{fatrays}

The currency of computation and core message type in FlexRender is the
\emph{fat ray}. They are so named because they carry additional state
information along with their geometric definition of an origin and a direction.
Their counterparts, \emph{slim rays}, consist of only the geometric components.

Specifically, a fat ray contains the following data:

\begin{itemize}
    \item The \textbf{type of ray} this is. Described in Section \ref{process}.
    \item The \textbf{source pixel} that this ray contributes to.
    \item The \textbf{bounce count}, or number of times this ray has reflected
        off a surface (to prevent infinite loops).
    \item The \textbf{origin and direction} of the ray.
    \item The ray's \textbf{transmittance}, or the amount that it contributes
        to the source pixel.
    \item The \textbf{emission} from a light source carried along the ray (if
        any). Described in Section \ref{shading}.
    \item The \textbf{target intersection point} of the ray, if any. Described
        in Section \ref{shading}.
    \item The \textbf{traversal state} of the top-level BVH. Described in
        Section \ref{traversal}.
    \item The \textbf{hit record}, which contains the worker, mesh, and $t$
        value of the nearest intersection.
    \item The \textbf{current worker} this ray should be sent to over the
        network.
    \item The \textbf{number of workers touched} by the ray so far. Not
        necessary for rendering. Only used for analysis.
    \item A \textbf{next pointer} for locally queueing rays as described in
        Section \ref{queues}. Obviously not valid over the network.
\end{itemize}

In total, the size of a fat ray is 128 bytes.

\subsection{General Types}
\label{types}

The core graphics machinery in FlexRender is fairly straightforward. A scene consists
of a collection of \emph{meshes}, which are stored as indexed face sets of vertices
(positions with normals and texture coordinates) and faces.

Each mesh is a assigned a \emph{material}, which is responsible for drawing the
mesh. A material consists of a \emph{shader} and potentially a set of bindings
from \emph{textures} to names in the shader.

A \emph{shader} is a piece of code that is run to compute the lighting on a
surface at a particular point.

A \emph{texture} is a either a 2D array of pixels (for image textures) or
a snippet of code (for procedural textures) that defines the value of
something across a surface. They are most commonly used for providing colored
detail across the face of a triangle.

All of the code used in graphics computation is shared between both our baseline
implementation and FlexRender. This ensures fair comparisons when we analyze our
results in Section \ref{results}.

\section{Render Preparation}
\label{prep}

\textbf{TODO}

\subsection{Configuration and Asset Distribution}
\label{sync}

\textbf{TODO: basic config data, establish worker connections, chunk up morton address space, read meshes, compute morton codes of their centroids, distribute to workers (also mention reading data off of shared network storage)}

\subsection{Parallel Construction of Spatial Acceleration Structures}
\label{parallelbvh}

\textbf{TODO: build BVH per mesh, then BVH of mesh bounds (still local), then send worker bounds to renderer and build BVH of worker bounds, distribute that to everyone}

\section{Ray Processing}
\label{process}

\textbf{TODO: mention the 3 types of rays}

\subsection {Ray Queues}
\label{queues}

\textbf{TODO: prefer rays more likely to terminate}

\subsection{Primary Ray Casting}
\label{primaryrays}

\textbf{TODO: runaway detection and prevention}

\subsection{Distributed BVH Traversal}
\label{traversal}

\textbf{TODO: modifications to stackless method}

\subsection{Illumination and Shading}
\label{shading}

\textbf{TODO: casting light rays backwards (light to object) and pushing them back into the system, checking for hit within epsilon of target}

\textbf{TODO: this stuff should go here instead:}

A \emph{shader} is a piece of code that is run to compute the lighting on a
surface at a particular point. The implementation of shaders in FlexRender is
through extensions to the Lua \cite{lua} programming language using the LuaJIT
\cite{luajit} implementation for speed. A shader may do any (or none) of the
following:

\begin{enumerate}
    \item Sample textures based on the name bindings assigned in the material
        definition.
    \item Compute a light value based on some implementation of a mathematical
        shading model and the local informtion at the point being shaded.
    \item Accumulate computed light values into the primary RGB buffers, or
        any auxilliary named buffer.
    \item Cast additional rays into the scene.
\end{enumerate}

\textbf{TODO: example phong shader snippet}

When new rays are cast into the scene from a shader, the results of that trace
are not immediately available. Instead the trace queues that ray for processing
and the traversal and shading systems ensure that the result of the trace will be
included in the final image.

In order for linearity and energy conservation to be respected, certain values
are inherited from the parent ray. In particular the source pixel is inherited
(so the ray contributes to the correct pixel in the final image) and the
desired transmittance along the new ray is multiplied with the transmittance of
the parent ray (to ensure energy conservation is preserved).

Casting rays from the shader can be used to implement several common visual
effects:

\begin{description}
    \item[Alpha Masking] Cast a new ray in the same direction with the full
        transmittance.
    \item[Reflection] Cast a new ray in the reflected direction with some
        fraction of the transmittance.
    \item[Refraction] Cast a new ray in the refracted direction with some
        fraction of the transmittance.
    \item[Monte Carlo Global Illumination] Cast sample rays in the surface
        hemisphere with fractional transmittances based on the number of samples.
\end{description}

\section{Render Completion}
\label{completion}

\textbf{TODO}

\subsection{Statistics and Monitoring}
\label{stats}

\textbf{TODO: primary casting progress, rays produced and killed, queue sizes}

\subsection{Image Synthesis}
\label{synthesis}

\textbf{TODO: request worker buffers and merge them into a single buffer linearly}

\chapter{Results}
\label{results}

\textbf{TODO}

\chapter{Future Work}
\label{futurework}

\textbf{TODO}

\section{System Optimizations}
\label{optimizations}

\textbf{TODO: replace morton coding with analysis and baking step, distribute all assets except geometry (eliminate final shading hop), prepass step to determine which workers should cast which primary rays}

\section{Memory Optimizations}
\label{memory}

\textbf{TODO: ray pools, cache line size, and queue alignment}

\section{GPGPU and Heterogenous Architectures}
\label{hetergenous}

\textbf{TODO: network interface, GPU workers, 10 GigE user mode DMA}

\clearpage
\bibliography{flexrender}
\bibliographystyle{plain}
%\addcontentsline{toc}{chapter}{Bibliography}

\section*{Image Results}

\end{document} much faster 
